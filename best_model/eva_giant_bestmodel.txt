TimmModel(
  (model): Eva(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1408, kernel_size=(14, 14), stride=(14, 14))
      (norm): Identity()
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (blocks): ModuleList(
      (0-39): 40 x EvaBlock(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): EvaAttention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path1): Identity()
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (drop_path2): Identity()
      )
    )
    (norm): Identity()
    (fc_norm): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
    (head_drop): Dropout(p=0.0, inplace=False)
    (head): Linear(in_features=1408, out_features=500, bias=True)
    (fc): Sequential(
      (0): Linear(in_features=1408, out_features=1024, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1024, out_features=500, bias=True)
    )
  )
)
